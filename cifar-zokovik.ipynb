{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zokovik/cifar-zokovik?scriptVersionId=187286728\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"b7feb193","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-07T22:49:42.836935Z","iopub.status.busy":"2024-07-07T22:49:42.836142Z","iopub.status.idle":"2024-07-07T22:49:43.553303Z","shell.execute_reply":"2024-07-07T22:49:43.552589Z"},"papermill":{"duration":0.726085,"end_time":"2024-07-07T22:49:43.555576","exception":false,"start_time":"2024-07-07T22:49:42.829491","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"8e76aa79","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:43.567506Z","iopub.status.busy":"2024-07-07T22:49:43.567133Z","iopub.status.idle":"2024-07-07T22:49:46.989165Z","shell.execute_reply":"2024-07-07T22:49:46.988317Z"},"papermill":{"duration":3.43061,"end_time":"2024-07-07T22:49:46.991491","exception":false,"start_time":"2024-07-07T22:49:43.560881","status":"completed"},"tags":[]},"outputs":[],"source":["# importing necesssary libraries\n","\n","import os\n","import pandas as pd\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":3,"id":"be4406dc","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:47.003153Z","iopub.status.busy":"2024-07-07T22:49:47.002732Z","iopub.status.idle":"2024-07-07T22:49:49.157683Z","shell.execute_reply":"2024-07-07T22:49:49.156868Z"},"papermill":{"duration":2.163344,"end_time":"2024-07-07T22:49:49.160099","exception":false,"start_time":"2024-07-07T22:49:46.996755","status":"completed"},"tags":[]},"outputs":[],"source":["# Building test and train CSV file, which contains details like image_path, class_name, etc.,. Can be used by Dataset class. \n","\n","def build_csv(data, csv_name):\n","    import csv\n","    \n","    with open(csv_name, \"w\", newline = \"\") as csvfile:\n","        writer = csv.writer(csvfile, delimiter = ',')\n","        writer.writerow([\"file_name\", \"file_path\", \"class_name\", \"class_index\"])\n","        for idx, partition in enumerate(os.listdir(data)):\n","            file = os.path.join(data, partition)\n","            for f in os.listdir(file):\n","                file_path = os.path.join(file, f)\n","                writer.writerow([f, file_path, partition, idx])\n","    \n","       \n","    return\n","    \n","            \n","    \n","train_data_loc = \"/kaggle/input/cifar10/cifar10/train\"\n","test_data_loc = \"/kaggle/input/cifar10/cifar10/test\"\n","build_csv(train_data_loc, \"train_csv\")\n","build_csv(test_data_loc, \"validation_csv\")"]},{"cell_type":"code","execution_count":4,"id":"f5f4d721","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:49.171205Z","iopub.status.busy":"2024-07-07T22:49:49.170914Z","iopub.status.idle":"2024-07-07T22:49:49.288687Z","shell.execute_reply":"2024-07-07T22:49:49.287489Z"},"papermill":{"duration":0.127003,"end_time":"2024-07-07T22:49:49.292263","exception":false,"start_time":"2024-07-07T22:49:49.16526","status":"completed"},"tags":[]},"outputs":[],"source":["# loading the test and train csv files\n","\n","df_test = pd.read_csv(\"train_csv\")\n","df_val = pd.read_csv(\"validation_csv\")"]},{"cell_type":"code","execution_count":5,"id":"efe9dfd5","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:49.303462Z","iopub.status.busy":"2024-07-07T22:49:49.303151Z","iopub.status.idle":"2024-07-07T22:49:49.325131Z","shell.execute_reply":"2024-07-07T22:49:49.32432Z"},"papermill":{"duration":0.029865,"end_time":"2024-07-07T22:49:49.327191","exception":false,"start_time":"2024-07-07T22:49:49.297326","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>file_path</th>\n","      <th>class_name</th>\n","      <th>class_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>29606_airplane.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/airplane/2...</td>\n","      <td>airplane</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>23684_airplane.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/airplane/2...</td>\n","      <td>airplane</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>46324_airplane.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/airplane/4...</td>\n","      <td>airplane</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>16513_airplane.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/airplane/1...</td>\n","      <td>airplane</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>40807_airplane.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/airplane/4...</td>\n","      <td>airplane</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>41608_deer.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/deer/41608...</td>\n","      <td>deer</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>6785_deer.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/deer/6785_...</td>\n","      <td>deer</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>17777_deer.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/deer/17777...</td>\n","      <td>deer</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>9202_deer.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/deer/9202_...</td>\n","      <td>deer</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>45749_deer.png</td>\n","      <td>/kaggle/input/cifar10/cifar10/train/deer/45749...</td>\n","      <td>deer</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["                file_name                                          file_path  \\\n","0      29606_airplane.png  /kaggle/input/cifar10/cifar10/train/airplane/2...   \n","1      23684_airplane.png  /kaggle/input/cifar10/cifar10/train/airplane/2...   \n","2      46324_airplane.png  /kaggle/input/cifar10/cifar10/train/airplane/4...   \n","3      16513_airplane.png  /kaggle/input/cifar10/cifar10/train/airplane/1...   \n","4      40807_airplane.png  /kaggle/input/cifar10/cifar10/train/airplane/4...   \n","...                   ...                                                ...   \n","49995      41608_deer.png  /kaggle/input/cifar10/cifar10/train/deer/41608...   \n","49996       6785_deer.png  /kaggle/input/cifar10/cifar10/train/deer/6785_...   \n","49997      17777_deer.png  /kaggle/input/cifar10/cifar10/train/deer/17777...   \n","49998       9202_deer.png  /kaggle/input/cifar10/cifar10/train/deer/9202_...   \n","49999      45749_deer.png  /kaggle/input/cifar10/cifar10/train/deer/45749...   \n","\n","      class_name  class_index  \n","0       airplane            0  \n","1       airplane            0  \n","2       airplane            0  \n","3       airplane            0  \n","4       airplane            0  \n","...          ...          ...  \n","49995       deer            9  \n","49996       deer            9  \n","49997       deer            9  \n","49998       deer            9  \n","49999       deer            9  \n","\n","[50000 rows x 4 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":6,"id":"59c82a55","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:49.339888Z","iopub.status.busy":"2024-07-07T22:49:49.339185Z","iopub.status.idle":"2024-07-07T22:49:49.347879Z","shell.execute_reply":"2024-07-07T22:49:49.347078Z"},"papermill":{"duration":0.016696,"end_time":"2024-07-07T22:49:49.349722","exception":false,"start_time":"2024-07-07T22:49:49.333026","status":"completed"},"tags":[]},"outputs":[],"source":["# Our Dataset Class \n","\n","from PIL import Image\n","from torch.utils.data import Dataset\n","class HHDataset(Dataset):\n","    def __init__(self, csv_file,transforms = None):\n","        self.csv_file = pd.read_csv(csv_file)\n","        self.transforms = transforms\n","        self.len = len(self.csv_file)\n","    def __getitem__(self, index):\n","                                    \n","        image = Image.open(self.csv_file.iloc[index][1])\n","        image = Image.open(self.csv_file.iloc[index][1]).convert(\"RGB\")\n","        if self.transforms:\n","            image = self.transforms(image)\n","        return image, self.csv_file.iloc[index][3]\n","        \n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":7,"id":"e616b7d4","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:49.360716Z","iopub.status.busy":"2024-07-07T22:49:49.360475Z","iopub.status.idle":"2024-07-07T22:49:50.920463Z","shell.execute_reply":"2024-07-07T22:49:50.919476Z"},"papermill":{"duration":1.568238,"end_time":"2024-07-07T22:49:50.922944","exception":false,"start_time":"2024-07-07T22:49:49.354706","status":"completed"},"tags":[]},"outputs":[],"source":["# lets use some failry simple transforms \n","\n","from torchvision import transforms\n","\n","# Define a transformation (if needed)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":8,"id":"4c8e45aa","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:50.935053Z","iopub.status.busy":"2024-07-07T22:49:50.934656Z","iopub.status.idle":"2024-07-07T22:49:50.943898Z","shell.execute_reply":"2024-07-07T22:49:50.942951Z"},"papermill":{"duration":0.017159,"end_time":"2024-07-07T22:49:50.94569","exception":false,"start_time":"2024-07-07T22:49:50.928531","status":"completed"},"tags":[]},"outputs":[],"source":["\"\"\" Defining our model, which consists of 3 CNN layers, each followed by a Relu activation and max-pooling. We then flatten out the resultant matrix, and \n"," pass it through a fully connected layer. \n","\"\"\"\n","\n","import torch.nn as nn\n","class Cmodel(nn.Module):\n","    def __init__(self):\n","        super(Cmodel, self).__init__()\n","        \n","        self.model = nn.Sequential(\n","        nn.Conv2d(in_channels = 3, out_channels = 64, stride = 1, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","    ,nn.Conv2d(in_channels = 64, out_channels = 128, stride = 1, kernel_size=3)\n","            ,nn.ReLU()\n","      ,nn.MaxPool2d(kernel_size = 3, stride = 2)\n","            ,nn.Conv2d(in_channels = 128, out_channels = 256, stride = 1, kernel_size=3)\n","            ,nn.ReLU()\n","        ,nn.MaxPool2d(kernel_size = 3, stride = 2),\n","        )\n","        \n","        self.linear = nn.Sequential(nn.Linear(3328* 13, 20)\n","       ,nn.Linear(20,10),\n","#                                    nn.Softmax()\n","                                   )\n","    def forward(self, x):\n","        out = self.model(x)\n","        out = out.view(-1, 3328* 13)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":9,"id":"188033c5","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:50.956714Z","iopub.status.busy":"2024-07-07T22:49:50.956446Z","iopub.status.idle":"2024-07-07T22:49:51.162112Z","shell.execute_reply":"2024-07-07T22:49:51.161234Z"},"papermill":{"duration":0.213469,"end_time":"2024-07-07T22:49:51.164107","exception":false,"start_time":"2024-07-07T22:49:50.950638","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[-0.2872, -0.1906, -0.0215, -0.0282,  0.2961, -0.0911,  0.1311, -0.1978,\n","         -0.2662,  0.1041]], grad_fn=<AddmmBackward0>)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# checking out, if it works as desired \n","\n","x = torch.randn(3,128,128)\n","c = Cmodel()\n","res = c(x)\n","res"]},{"cell_type":"code","execution_count":10,"id":"b64abfb5","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:51.175776Z","iopub.status.busy":"2024-07-07T22:49:51.175494Z","iopub.status.idle":"2024-07-07T22:49:51.295848Z","shell.execute_reply":"2024-07-07T22:49:51.295065Z"},"papermill":{"duration":0.129522,"end_time":"2024-07-07T22:49:51.298927","exception":false,"start_time":"2024-07-07T22:49:51.169405","status":"completed"},"tags":[]},"outputs":[],"source":["# creating the data loaders for training data and test data\n","\n","from torch.utils.data import DataLoader\n","train_data = HHDataset(csv_file = \"/kaggle/working/train_csv\", transforms = transform )\n","val_data = HHDataset(csv_file = \"/kaggle/working/validation_csv\", transforms = transform)\n","\n","\n","trainLoader = DataLoader(train_data,batch_size = 512, shuffle = True)\n","testLoader = DataLoader(val_data, batch_size = 512, shuffle = True)\n"]},{"cell_type":"code","execution_count":11,"id":"e22be71f","metadata":{"execution":{"iopub.execute_input":"2024-07-07T22:49:51.311925Z","iopub.status.busy":"2024-07-07T22:49:51.311299Z","iopub.status.idle":"2024-07-08T00:33:29.609329Z","shell.execute_reply":"2024-07-08T00:33:29.608328Z"},"papermill":{"duration":6218.306765,"end_time":"2024-07-08T00:33:29.611781","exception":false,"start_time":"2024-07-07T22:49:51.305016","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_25/3604617531.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  image = Image.open(self.csv_file.iloc[index][1])\n","/tmp/ipykernel_25/3604617531.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  image = Image.open(self.csv_file.iloc[index][1]).convert(\"RGB\")\n","/tmp/ipykernel_25/3604617531.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  return image, self.csv_file.iloc[index][3]\n"]},{"name":"stdout","output_type":"stream","text":["tensor(2.3075, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","50 correct\n","tensor(1.8888, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","3511 correct\n","tensor(1.6278, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","9315 correct\n","tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","15751 correct\n","epoch0 completed 0.34492\n","tensor(1.5937, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","224 correct\n","tensor(1.5132, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","7301 correct\n","tensor(1.3900, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14776 correct\n","tensor(1.4628, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","22401 correct\n","epoch1 completed 0.4817\n","tensor(1.2806, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","276 correct\n","tensor(1.3394, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","8329 correct\n","tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","16621 correct\n","tensor(1.3534, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","25030 correct\n","epoch2 completed 0.53732\n","tensor(1.1777, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","303 correct\n","tensor(1.1587, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","9025 correct\n","tensor(1.1872, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","17813 correct\n","tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","26852 correct\n","epoch3 completed 0.57776\n","tensor(1.1448, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","307 correct\n","tensor(1.1363, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","9588 correct\n","tensor(1.1586, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","18951 correct\n","tensor(1.0430, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28372 correct\n","epoch4 completed 0.60984\n","tensor(1.0395, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","332 correct\n","tensor(1.1422, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","10080 correct\n","tensor(0.9263, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","19678 correct\n","tensor(1.0328, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","29400 correct\n","epoch5 completed 0.63172\n","tensor(1.0381, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","326 correct\n","tensor(1.0344, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","10320 correct\n","tensor(0.9802, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","20428 correct\n","tensor(1.0350, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","30524 correct\n","epoch6 completed 0.6557\n","tensor(0.9979, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","325 correct\n","tensor(0.9778, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","10606 correct\n","tensor(0.9391, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","20931 correct\n","tensor(0.9630, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","31365 correct\n","epoch7 completed 0.6729\n","tensor(0.8301, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","361 correct\n","tensor(0.9148, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","10798 correct\n","tensor(0.9050, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","21467 correct\n","tensor(0.9242, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","32000 correct\n","epoch8 completed 0.68726\n","tensor(0.7857, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","380 correct\n","tensor(0.8080, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","11356 correct\n","tensor(0.8973, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","22149 correct\n","tensor(0.8310, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","32917 correct\n","epoch9 completed 0.70726\n","tensor(0.7372, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","390 correct\n","tensor(0.8357, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","11361 correct\n","tensor(0.7758, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","22372 correct\n","tensor(0.8155, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","33365 correct\n","epoch10 completed 0.71534\n","tensor(0.6821, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","395 correct\n","tensor(0.7446, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","11666 correct\n","tensor(0.7949, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","22928 correct\n","tensor(0.7582, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","34086 correct\n","epoch11 completed 0.73174\n","tensor(0.6855, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","389 correct\n","tensor(0.7490, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","11862 correct\n","tensor(0.7163, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","23246 correct\n","tensor(0.7817, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","34649 correct\n","epoch12 completed 0.74374\n","tensor(0.6042, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","401 correct\n","tensor(0.8276, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12179 correct\n","tensor(0.7071, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","23810 correct\n","tensor(0.7507, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","35293 correct\n","epoch13 completed 0.7561\n","tensor(0.6609, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","402 correct\n","tensor(0.6502, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12267 correct\n","tensor(0.6558, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","24096 correct\n","tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","35697 correct\n","epoch14 completed 0.76504\n","tensor(0.5920, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","405 correct\n","tensor(0.6773, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12447 correct\n","tensor(0.6755, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","24292 correct\n","tensor(0.6825, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","36035 correct\n","epoch15 completed 0.77278\n","tensor(0.5525, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","422 correct\n","tensor(0.5726, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12587 correct\n","tensor(0.6031, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","24631 correct\n","tensor(0.5936, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","36606 correct\n","epoch16 completed 0.78526\n","tensor(0.5868, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","410 correct\n","tensor(0.4757, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12702 correct\n","tensor(0.6478, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","24916 correct\n","tensor(0.6090, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","37000 correct\n","epoch17 completed 0.79356\n","tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","410 correct\n","tensor(0.5348, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12880 correct\n","tensor(0.5542, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","25075 correct\n","tensor(0.6058, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","37425 correct\n","epoch18 completed 0.80216\n","tensor(0.5823, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","396 correct\n","tensor(0.5464, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","12957 correct\n","tensor(0.5286, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","25417 correct\n","tensor(0.5285, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","37787 correct\n","epoch19 completed 0.81048\n","tensor(0.4748, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","434 correct\n","tensor(0.4684, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13109 correct\n","tensor(0.4827, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","25613 correct\n","tensor(0.5460, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","38156 correct\n","epoch20 completed 0.8183\n","tensor(0.4818, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","416 correct\n","tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13205 correct\n","tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","25793 correct\n","tensor(0.5261, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","38362 correct\n","epoch21 completed 0.82252\n","tensor(0.4340, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","438 correct\n","tensor(0.4366, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13360 correct\n","tensor(0.4259, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","26304 correct\n","tensor(0.4489, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","39028 correct\n","epoch22 completed 0.83684\n","tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","449 correct\n","tensor(0.4075, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13509 correct\n","tensor(0.5009, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","26432 correct\n","tensor(0.4268, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","39392 correct\n","epoch23 completed 0.84514\n","tensor(0.4141, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","444 correct\n","tensor(0.4626, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13655 correct\n","tensor(0.4311, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","26709 correct\n","tensor(0.5155, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","39653 correct\n","epoch24 completed 0.8506\n","tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","450 correct\n","tensor(0.4120, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","13875 correct\n","tensor(0.3373, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","27037 correct\n","tensor(0.4173, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","40052 correct\n","epoch25 completed 0.85878\n","tensor(0.3599, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","447 correct\n","tensor(0.3773, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14034 correct\n","tensor(0.3746, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","27343 correct\n","tensor(0.4911, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","40505 correct\n","epoch26 completed 0.86828\n","tensor(0.3510, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","446 correct\n","tensor(0.3696, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14013 correct\n","tensor(0.3673, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","27429 correct\n","tensor(0.3796, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","40799 correct\n","epoch27 completed 0.87564\n","tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","449 correct\n","tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14130 correct\n","tensor(0.3159, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","27578 correct\n","tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","41019 correct\n","epoch28 completed 0.87946\n","tensor(0.2649, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","465 correct\n","tensor(0.2955, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14291 correct\n","tensor(0.3655, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28008 correct\n","tensor(0.3932, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","41582 correct\n","epoch29 completed 0.89116\n","tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","454 correct\n","tensor(0.3185, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14231 correct\n","tensor(0.3839, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","27895 correct\n","tensor(0.3593, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","41466 correct\n","epoch30 completed 0.8899\n","tensor(0.2345, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","470 correct\n","tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14472 correct\n","tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28238 correct\n","tensor(0.3014, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","41991 correct\n","epoch31 completed 0.9003\n","tensor(0.2522, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","471 correct\n","tensor(0.3140, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14296 correct\n","tensor(0.2579, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28204 correct\n","tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","42031 correct\n","epoch32 completed 0.90136\n","tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","470 correct\n","tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14578 correct\n","tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28641 correct\n","tensor(0.2730, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","42441 correct\n","epoch33 completed 0.91006\n","tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","470 correct\n","tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14595 correct\n","tensor(0.2196, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28549 correct\n","tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","42461 correct\n","epoch34 completed 0.9103\n","tensor(0.2373, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","478 correct\n","tensor(0.1983, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14745 correct\n","tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","28844 correct\n","tensor(0.2329, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","42846 correct\n","epoch35 completed 0.91882\n","tensor(0.1540, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","485 correct\n","tensor(0.1839, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14863 correct\n","tensor(0.1963, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","29206 correct\n","tensor(0.2015, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","43369 correct\n","epoch36 completed 0.93032\n","tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","481 correct\n","tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14984 correct\n","tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","29212 correct\n","tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","43379 correct\n","epoch37 completed 0.93014\n","tensor(0.1429, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","489 correct\n","tensor(0.1708, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","14944 correct\n","tensor(0.1955, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","29492 correct\n","tensor(0.2160, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","43666 correct\n","epoch38 completed 0.93596\n","tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","482 correct\n","tensor(0.1518, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","15055 correct\n","tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","29561 correct\n","tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>) =================\n","43916 correct\n","epoch39 completed 0.942\n"]}],"source":["# trainging our model.\n","\n","epochs = 40\n","import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(device)\n","model = Cmodel().to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","\n","\n","\n","for epoch in range(epochs):\n","  \n","    model.train()\n","    \n","    correct = total = 0\n","    for batch_size, (data, target) in enumerate(trainLoader):\n","        \n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","\n","        target = target.float()\n","        output = model(data)\n","\n","        output = output.squeeze()\n","        \n","        target = target.to(torch.int64)\n","\n","        # notice that, Cross entropy loss function, by itself converts the outputs to softmax for prediction, and also converts the target to one-hot\n","#         encoded values\n","        loss = criterion(output, target)\n","        \n","        \n","\n","        loss.backward()\n","        \n","        optimizer.step()\n","\n","        total += target.size(0)\n","        \n","        predicted_classes = torch.argmax(output, dim=1)\n","        \n","        correct += (predicted_classes == target).sum().item()\n","        \n","        \n","        if (batch_size % 30 == 0):\n","            print(loss, \"=================\")\n","            print(correct, \"correct\")\n","    \n","    \n","    \n","    print(f\"epoch{epoch} completed\", correct/total)\n","    \n","        "]},{"cell_type":"code","execution_count":12,"id":"46c4178a","metadata":{"execution":{"iopub.execute_input":"2024-07-08T00:33:29.656975Z","iopub.status.busy":"2024-07-08T00:33:29.656576Z","iopub.status.idle":"2024-07-08T00:34:35.215372Z","shell.execute_reply":"2024-07-08T00:34:35.214378Z"},"papermill":{"duration":65.605878,"end_time":"2024-07-08T00:34:35.239878","exception":false,"start_time":"2024-07-08T00:33:29.634","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_25/3604617531.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  image = Image.open(self.csv_file.iloc[index][1])\n","/tmp/ipykernel_25/3604617531.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  image = Image.open(self.csv_file.iloc[index][1]).convert(\"RGB\")\n","/tmp/ipykernel_25/3604617531.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  return image, self.csv_file.iloc[index][3]\n"]},{"name":"stdout","output_type":"stream","text":["val accuracy 0.6729\n"]}],"source":["# testing our validation accuracy\n","\n","\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for data, labels in testLoader:\n","\n","            data, labels = data.to(device), labels.to(device)\n","            outputs = model(data)\n","\n","            outputs = outputs.squeeze()\n","#                 predicted = (outputs > 0.5).int()\n","\n","            total += labels.size(0)\n","            predicted_classes = torch.argmax(outputs, dim=1)\n","\n","            correct += (predicted_classes == labels).sum().item()\n","\n","\n","\n","#         print(correct, total)\n","    accuracy = correct / total\n","    print(f\"val accuracy {accuracy}\")"]},{"cell_type":"code","execution_count":null,"id":"592e07ed","metadata":{"papermill":{"duration":0.021831,"end_time":"2024-07-08T00:34:35.284735","exception":false,"start_time":"2024-07-08T00:34:35.262904","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"792be694","metadata":{"papermill":{"duration":0.02217,"end_time":"2024-07-08T00:34:35.328995","exception":false,"start_time":"2024-07-08T00:34:35.306825","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4255cc16","metadata":{"papermill":{"duration":0.022548,"end_time":"2024-07-08T00:34:35.373876","exception":false,"start_time":"2024-07-08T00:34:35.351328","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e2b6513b","metadata":{"papermill":{"duration":0.022626,"end_time":"2024-07-08T00:34:35.419545","exception":false,"start_time":"2024-07-08T00:34:35.396919","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":42895,"sourceId":76089,"sourceType":"datasetVersion"}],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":6297.642609,"end_time":"2024-07-08T00:34:37.8073","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-07T22:49:40.164691","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}